services:
  pagi-python-agent:
    container_name: pagi-python-agent
    build:
      context: ./backend-python-agent
    environment:
      - PY_AGENT_PORT=8000
      - GO_BFF_URL=http://pagi-go-bff:${GO_BFF_PORT:-8002}
      - MODEL_GATEWAY_GRPC_HOST=pagi-go-model-gateway
      - MODEL_GATEWAY_GRPC_PORT=${MODEL_GATEWAY_GRPC_PORT:-50051}
      - MODEL_GATEWAY_GRPC_TIMEOUT_SECONDS=5
      - REQUEST_TIMEOUT_SECONDS=${REQUEST_TIMEOUT_SECONDS:-2}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    ports:
      - "${PY_AGENT_PORT:-8000}:8000"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys; urllib.request.urlopen('http://localhost:8000/health').read(); sys.exit(0)"]
      interval: 5s
      timeout: 3s
      retries: 10

  pagi-rust-sandbox:
    container_name: pagi-rust-sandbox
    build:
      context: ./backend-rust-sandbox
    environment:
      - RUST_SANDBOX_PORT=8001
      - REQUEST_TIMEOUT_SECONDS=${REQUEST_TIMEOUT_SECONDS:-2}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    ports:
      - "${RUST_SANDBOX_PORT:-8001}:8001"
    healthcheck:
      test: ["CMD", "sh", "-c", "wget -qO- http://localhost:8001/health >/dev/null 2>&1"]
      interval: 5s
      timeout: 3s
      retries: 10

  pagi-mock-memory:
    container_name: pagi-mock-memory
    build:
      context: ./scripts
      dockerfile: Dockerfile
    environment:
      - MEMORY_MOCK_PORT=8003
      - REQUEST_TIMEOUT_SECONDS=${REQUEST_TIMEOUT_SECONDS:-2}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    ports:
      - "${MEMORY_MOCK_PORT:-8003}:8003"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys; urllib.request.urlopen('http://localhost:8003/health').read(); sys.exit(0)"]
      interval: 5s
      timeout: 3s
      retries: 10

  pagi-go-bff:
    container_name: pagi-go-bff
    build:
      context: ./backend-go-bff
    environment:
      - GO_BFF_PORT=8002
      - PY_AGENT_URL=http://pagi-python-agent:8000
      - RUST_SANDBOX_URL=http://pagi-rust-sandbox:8001
      - MEMORY_URL=http://pagi-mock-memory:8003
      - REQUEST_TIMEOUT_SECONDS=${REQUEST_TIMEOUT_SECONDS:-2}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    ports:
      - "${GO_BFF_PORT:-8002}:8002"
    depends_on:
      pagi-python-agent:
        condition: service_healthy
      pagi-rust-sandbox:
        condition: service_healthy
      pagi-mock-memory:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "sh", "-c", "wget -qO- http://localhost:8002/health >/dev/null 2>&1"]
      interval: 5s
      timeout: 3s
      retries: 10

  pagi-go-model-gateway:
    container_name: pagi-go-model-gateway
    build:
      context: ./backend-go-model-gateway
    environment:
      - MODEL_GATEWAY_GRPC_PORT=${MODEL_GATEWAY_GRPC_PORT:-50051}
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # LLM provider switching
      - LLM_PROVIDER=${LLM_PROVIDER:-openrouter}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL_NAME=${OPENROUTER_MODEL_NAME:-mistralai/mistral-7b-instruct:free}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://localhost:11434}
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-llama3}
      - REQUEST_TIMEOUT_SECONDS=${REQUEST_TIMEOUT_SECONDS:-5}
    ports:
      - "${MODEL_GATEWAY_GRPC_PORT:-50051}:50051"

